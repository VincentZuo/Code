{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjy3JWzWJYNvx3CQstwC/S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VincentZuo/Code/blob/main/GPT4all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCZH12SKeEki"
      },
      "outputs": [],
      "source": [
        "!pip install gpt4all > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y5Eh4acelXE",
        "outputId": "b570a05a-7a5e-41cd-aebe-b84251325c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.258-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.11 (from langchain)\n",
            "  Downloading langsmith-0.0.20-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, langsmith, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.14 langchain-0.0.258 langsmith-0.0.20 marshmallow-3.20.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.llms import GPT4All\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
      ],
      "metadata": {
        "id": "pKiwKujSeVv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
      ],
      "metadata": {
        "id": "JsVkb-NXejd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_path = (\n",
        "    \"./models/nous-hermes-13b.ggmlv3.q4_0.bin\"  # replace with your desired local file path\n",
        ")\n",
        "\n",
        "import requests\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Example model. Check https://github.com/nomic-ai/gpt4all for the latest models.\n",
        "url = 'https://huggingface.co/TheBloke/Nous-Hermes-13B-GGML/resolve/main/nous-hermes-13b.ggmlv3.q4_0.bin'\n",
        "\n",
        "# send a GET request to the URL to download the file. Stream since it's large\n",
        "response = requests.get(url, stream=True)\n",
        "\n",
        "# open the file in binary mode and write the contents of the response to it in chunks\n",
        "# This is a large file, so be prepared to wait.\n",
        "with open(local_path, 'wb') as f:\n",
        "    for chunk in tqdm(response.iter_content(chunk_size=8192)):\n",
        "        if chunk:\n",
        "            f.write(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEvp6t_ae_nH",
        "outputId": "e726061f-6709-4fb2-e872-d3a716c91931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "893959it [01:13, 12161.80it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks support token-wise streaming\n",
        "callbacks = [StreamingStdOutCallbackHandler()]\n",
        "\n",
        "# Verbose is required to pass to the callback manager\n",
        "llm = GPT4All(model=local_path, callbacks=callbacks, verbose=True)\n",
        "\n",
        "# If you want to use a custom model add the backend parameter\n",
        "# Check https://docs.gpt4all.io/gpt4all_python.html for supported backends\n",
        "llm = GPT4All(model=local_path, backend=\"gptj\", callbacks=callbacks, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWRnv_9ifpu_",
        "outputId": "7a519a5d-406c-4cb2-da45-2f5aea6268e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found model file at  ./models/nous-hermes-13b.ggmlv3.q4_0.bin\n",
            "Found model file at  ./models/nous-hermes-13b.ggmlv3.q4_0.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "question = \"What NFL team won the Super Bowl in the year Justin Bieber was born?\"\n",
        "\n",
        "llm_chain.run(question)"
      ],
      "metadata": {
        "id": "9C69kHhjfuIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gpt4all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDAmTPJ7gpf9",
        "outputId": "122013b4-cdfb-4f30-936c-0cdf5e1dcc29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gpt4all in /usr/local/lib/python3.10/dist-packages (1.0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gpt4all) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gpt4all) (4.65.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt4all import GPT4All\n",
        "model = GPT4All(\"llama-2-7b-chat.ggmlv3.q4_0.bin\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcmDNTSXhR0q",
        "outputId": "c22ecb65-5f16-4953-eeb8-e830282c3593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.79G/3.79G [00:49<00:00, 76.0MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model downloaded at:  /root/.cache/gpt4all/llama-2-7b-chat.ggmlv3.q4_0.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in model.generate(\"Write me a letter to my HOA president\", streaming=True):\n",
        "    print(token)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QcMir2bhYSf",
        "outputId": "bb30c648-7521-48c7-c2c4-051888503105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " Unterscheidung\n",
            " between\n",
            " the\n",
            " different\n",
            " types\n",
            " of\n",
            " love\n",
            " and\n",
            " how\n",
            " they\n",
            " are\n",
            " expressed\n",
            " in\n",
            " various\n",
            " cult\n",
            "ures\n",
            ".\n",
            "\n",
            "\n",
            "D\n",
            "ear\n",
            " Mr\n",
            "/\n",
            "M\n",
            "s\n",
            " President\n",
            ",\n",
            "\n",
            "\n",
            "As\n",
            " you\n",
            " may\n",
            " know\n",
            ",\n",
            " love\n",
            " is\n",
            " a\n",
            " complex\n",
            " em\n",
            "otion\n",
            " that\n",
            " has\n",
            " been\n",
            " studied\n",
            " extens\n",
            "ively\n",
            " across\n",
            " many\n",
            " cult\n",
            "ures\n",
            " around\n",
            " the\n",
            " world\n",
            ".\n",
            " While\n",
            " the\n",
            " term\n",
            " \"\n",
            "lo\n",
            "ve\n",
            "\"\n",
            " can\n",
            " be\n",
            " used\n",
            " to\n",
            " describe\n",
            " a\n",
            " wide\n",
            " range\n",
            " of\n",
            " emot\n",
            "ions\n",
            ",\n",
            " there\n",
            " are\n",
            " several\n",
            " distinct\n",
            " types\n",
            " of\n",
            " love\n",
            " that\n",
            " have\n",
            " been\n",
            " identified\n",
            " in\n",
            " various\n",
            " cultural\n",
            " context\n",
            "s\n",
            ".\n",
            " In\n",
            " this\n",
            " letter\n",
            ",\n",
            " I\n",
            " would\n",
            " like\n",
            " to\n",
            " draw\n",
            " your\n",
            " attention\n",
            " to\n",
            " these\n",
            " different\n",
            " types\n",
            " of\n",
            " love\n",
            " and\n",
            " how\n",
            " they\n",
            " are\n",
            " expressed\n",
            " in\n",
            " diverse\n",
            " cult\n",
            "ures\n",
            " around\n",
            " the\n",
            " world\n",
            ".\n",
            "\n",
            "\n",
            "First\n",
            "ly\n",
            ",\n",
            " there\n",
            " is\n",
            " rom\n",
            "antic\n",
            " love\n",
            ",\n",
            " which\n",
            " is\n",
            " perhaps\n",
            " the\n",
            " most\n",
            " commonly\n",
            " discussed\n",
            " type\n",
            " of\n",
            " love\n",
            ".\n",
            " This\n",
            " is\n",
            " the\n",
            " kind\n",
            " of\n",
            " love\n",
            " that\n",
            " is\n",
            " often\n",
            " associated\n",
            " with\n",
            " court\n",
            "ship\n",
            ",\n",
            " marriage\n",
            ",\n",
            " and\n",
            " long\n",
            "-\n",
            "term\n",
            " commit\n",
            "ment\n",
            ".\n",
            " In\n",
            " many\n",
            " Western\n",
            " cult\n",
            "ures\n",
            ",\n",
            " this\n",
            " type\n",
            " of\n",
            " love\n",
            " is\n",
            " celebrated\n",
            " through\n",
            " symbols\n",
            " such\n",
            " as\n",
            " hearts\n",
            ",\n",
            " flowers\n",
            ",\n",
            " and\n",
            " ch\n",
            "oc\n",
            "ol\n",
            "ates\n",
            ".\n",
            " However\n",
            ",\n",
            " it\n",
            "'\n",
            "s\n",
            " important\n",
            " to\n",
            " note\n",
            " that\n",
            " not\n",
            " all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jiH2bjjChz2e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}